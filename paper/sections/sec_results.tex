% !TEX root = ../Victorvan Herel2025_Thesis.tex

\chapter{Results}\label{ch:results}

\section{Experiment 1: Copyleft clause}

\subsection{Determining X for Majority-of-X}

As discussed in Chapter~\ref{ch:method}, we will first determine the value of X for a Majority-of-X answer construction. To do this, we need need to define values for X, based on where we observe the stochasticity to have stabilised. We will do this by making observations up to the value of X = 15, where a requirement for further runs would lower the credibility of the model. \\

After running the models for multiple times, we can render the following accuracy table of the first 15 Majority-of-X answers for each LLM. It is important to understand that ordering of individual runs is always preserved while calculating this answer. As such, evening out the stochastic behavior is fair and not based on arbitrary decisions. \\

% Autogenerated file: Copyleft rolling X accuracy table, percentage
\begin{table}[h]
	\label{tab:copyleft-rollingx-perc}
	\centering
	\input{autogen/copyleft_majority_accuracies_rollingx_perc.tex}
	\caption{Accuracy scores for copyleft detection, rolling value of X for Majority-of-X results}
\end{table}

Or in absolute numbers, out of a total of 114 licenses which were given a Copyleft categorization by the OSADL, the following table shows: \\

% Autogenerated file: Copyleft rolling X accuracy table, absolute values
\begin{table}[h]
	\label{tab:copyleft-rollingx-absolute}
	\centering
	\input{autogen/copyleft_majority_accuracies_rollingx_absolute.tex}
	\caption{Absolute number of accurate results for copyleft detection, rolling value of X for Majority-of-X results}
\end{table}

Let's now examine these results individually per model. \\

\textbf{deepseek-r1:8b:} This model appears as the second strongest model for this task in the list. It is also the second most varying model, given that the amount of results it scores correctly varies at 4 points throughout the evolution from Majority-of-1 to Majority-of-15. In terms of absolute change, the most significant change happens at 3 to 5. After this, any change remains within the bounds of 2. At X=7 and onwards, any changes remain within the bounds of 1. For this reason, we choose \textbf{7 for the value of X for deepseek-r1:8b}. \\

\textbf{gemma3:4b:} The gemma3 model appears very stable, already stabilising fully at X = 3. Due to this consistency, we choose \textbf{3 for the value of X for gemma3:4b}. \\

\textbf{llama3:} A varying model which offers great speed and relatively strong accuracy, while among the lower scores in the results. Unlike the other models, this model does not reach a stable point within the first Majority-of-15 result sets. We choose \textbf{15 for the value of X for llama3}, as it is a fast model where making multiple runs is not an issue. \\

\textbf{qwen3:8b:} This model is the strongest on the list, while also having the longest average runtime. We see that for this model, only two points of change occur in the entire table, and this model is therefore very consistent, like gemma3:4b discussed before. Given the stochastic nature of LLM's, choosing value 1 is not appropriate. For this reason, we choose \textbf{3 for the value of X for qwen3:8b}.

\subsection{Accuracy scoring}

We consider the results of the copyleft detection experiment first as follows per model below. For each model, we will examine the average accuracy which individual runs without majority vote construction. We do this to show the difference to the accuracy of the majority vote construction method, and lastly, tables 5.3 through 5.6 will show confusion matrices which count the number of licenses that are actually copyleft in the top row, split up by their assessment by the LLM over the two columns. The same is true for the actually permissive licenses in the bottom row. It is important to remind ourselves that the total number of licenses in these matrices will always be 114, which is the number of licenses that were assessed by the OSADL. \\

\textbf{Deepseek R1:8b:} This model is very inconsistent with its answers, answering differently across runs for 28 licenses in the dataset. Additionally, this model classifies 2 specific licenses incorrectly on all its runs. We will discuss this rather peculiar result after the listing of direct results. In a majority configuration however, we note that the accuracy increases (107 licenses correctly classified, as opposed to 104 in the best run). This suggests that this model does benefit from a majority vote setup. Notably, this model also does not make any false positive detections.

\textbf{Average accuracy:} 89.10\%

\textbf{Majority-of-7 accuracy:} 92.98\% (106/114)

\begin{table}[h]
	\label{tab:deepseekr1-confmatrix}
	\centering
	\input{autogen/copyleft_summary_deepseek-r1-8b_majority_of_7.tex}
	\caption{Deepseek R1:8b confusion matrix (Majority-of-7)}
\end{table}
\newpage
\textbf{Gemma3:4b:} This model performed better, scoring an average accuracy across runs of 83.62\% (97/116). Its mistakes are also exclusively failures to detect a present copyleft license. The confusion matrix for the majority vote is given in Table~\ref{tab:gemma3-confmatrix}, which scored the same accuracy as the average accuracy. The model is very consistent, only differing in responses across runs for the MPL-1.1 license and the MPL-2.0-no-copyleft-exception license. Interestingly, this model also has the property of giving no false positive detections.

\textbf{Average accuracy:} 83.33\%

\textbf{Majority-of-3 accuracy:} 83.33\% (95/114)

\begin{table}[h]
	\label{tab:gemma3-confmatrix}
	\centering
	\input{autogen/copyleft_summary_gemma3-4b_majority_of_3.tex}
	\caption{Gemma3:4b confusion matrix (Majority-of-3)}
\end{table}

\textbf{Llama3:} This model performs slightly better than Gemma3:4b, and is also slightly more varied. It provides a fast baseline of what simple models can achieve, allowing you to trade a minor amount of accuracy for faster runtime. However, this model is varied and requires more than 15 runs to become stable, as such, answers provided by this model should be considered as largely stochastic still.

\textbf{Average accuracy:} 83.74\%

\textbf{Majority-of-15 accuracy:} 86.84\% (99/114)

\begin{table}[h]
	\label{tab:llama3-confmatrix}
	\centering
	\input{autogen/copyleft_summary_llama3_majority_of_15.tex}
	\caption{Llama3:8b confusion matrix (Majority-of-15)}
\end{table}

\textbf{Qwen3:8b:} This model is the best model of the selected models for this task. It however doesn't really benefit from the majority vote decision setup, like we have seen for the Deepseek model. Instead, its runs generally are very accurate, outclassing all other 3 models that were included in this experiment, we also observe here that the model actually has a disadvantage when it is placed in a smaller majority configuration like Majority-of-3, as it is susceptible to the first runs that it is fed.

\textbf{Average accuracy:} 96.49\%

\textbf{Majority-of-3 accuracy:} 96.49\% (110/114)

\begin{table}[h]
	\label{tab:qwen3-confmatrix}
	\centering
	\input{autogen/copyleft_summary_qwen3-8b_majority_of_3.tex}
	\caption{Qwen3:8b confusion matrix (Majority-of-3)}
\end{table}

\subsection{General conlusions}

These accuracy characteristics display an interesting property: The accuracy of a given model in a majority configuration will continue rising until it stabilises around a given point. This is a logical consequence of the fact that, while an answer for an individual license is deterministic, it will produce an average accuracy for that individual license as more runs are added to the data in consideration. As our accuracy measure is an aggregate of those for individual runs, this measure will display the same property.

It is then a logical conclusion to say that a model will, generally, answer wrongly for a subset of the input licenses. And in this avenue, we examine whether or not we can identify any reasons for these mistakes made by the models. We start by examining the two licenses which all models got consistently wrong.

\subsubsection{Universally false inferences}

The Gemma3, Deepseek R1 and Qwen3 model all failed to classify two licenses correctly, looking into the thinking of the models when making this decision, we can explain why:
\begin{itemize}
	\item \textbf{IPL-1.0:} The IBM Public License is a complex case because it handles source code redistribution and binary object redistribution entirely differently. We examine specifically its Section 3 Requirements. This mentions the following:
	\begin{itemize}
		\item "When the Program is made available in source code form: a. it must be made available under this Agreement; and b. a copy of this Agreement must be included with each copy of the Program." This section tells us that source code redistribution is strongly copyleft, requiring the same license is used for the derivative work created.
		\item "A contributor may choose to distribute the Program in object code form under its own license agreement, provided that: [...]" This section governs binary delivery, and it does impose that whichever license agreement you use, it complies with the IPL-1.0, and must disclaim warranty on behalf of the contributors, excluding them from liabilities, damages, ... much like the MIT license. It goes on to permit the new license to differ, but that such different clauses are only offered by the redistributing contributor alone.
		This difference between handling of source code redistribution and binary object redistribution seems to confuse our models. The option to redistribute under a different license, given specific requirements, is not a copyleft clause. As such, the models decide to classify this license as permissive in almost all runs.
	\end{itemize}
	
	\item \textbf{Sleepycat:} The sleepycat license is also always classified incorrectly. In this case, the source of confusion is a bit more obvious. The sleepycat license itself is actually 3 licenses which were concatenated together. Because of this, and the predictable nature of the format of these licenses, the models get confused when running inference, treating each license referenced as a separate question. As a result, it fails to comply with the answer format provided, meaning automatic detection of the answer fails as well for Deepseek R1 and Qwen3. For Gemma3, it actually is capable of considering the entire license as its own block, however it is mistaken in handling of the license itself, missing the fact that the Sleepycat section of this license is indeed BSD-3 Clause, but adds an additional clause which imposes a Copyleft clause to this format.
\end{itemize}

\subsubsection{Individually false inferences}

Aside from the inaccuracies produced by all models, each model also had individual licenses it struggled to assess correctly. In this section, we examine these inaccuracies to determine if there is other model-specific issues. We will do this on a per-model basis. \\

\textbf{Deepseek R1:} We see this model struggle in particular for the EPL-1.0, EPL-2.0 and MS-RL licenses. It also is indecisive for the CDDL-1.0 and CDDL-1.1 licenses, where the model's accuracy approaches 50\% as more runs are made.

For the EPL licenses, the copyleft property is constructed and not explicitly embedded into the license. By this we mean that both of these licenses require that source code be distributed under the same terms (section 3.2 of both licenses), and then separately from that, all forms of distribution are required to be accompanied by a source code distribution. It is this concept that the model appears to fail to identify, despite explicitly calling out both elements to come to the copyleft requirement in its reasoning. We have also looked at an example of the GPL-1.0-only license which is more widely known and used, which makes a similar construction to come to the copyleft requirement. Deepseek is not mistaken in the case of the GPL-1.0-only license, which seems to suggest the model may also be making use of more widely available knowledge it consumed in its training.

For the MS-RL license, the copyleft clause is more explicit, and contained within section 3A which states that if you distribute a file in any form (source code, binary object, ...) which contains code from the licensed work, you must distribute the source code and the license. It states that the license will govern the distributed file. This appears to be something that the model misses, as it does mention this section in every explanation, but writes it away as being about ensuring the license is propagated with derivative works, and not set up to govern those works. \\

\textbf{Gemma3:} This model exhibits a very interesting property, where it is, as already previously described, very consistent. We also see this in its result forming, where the overview shows that in nearly all licenses, it will answer the same all the time. Sadly, this model doesn't appear to always include an explanation, and when it does, its explanations are very short. We recall however that this model only made false negative inaccuracies, where it says a copyleft license is permissive. When we look at the mistakes from this perspective, a pattern starts to form where the model very often states something along the lines of: "... grants a broad range of permissions.", to which the logical conclusion is to state that the license is a permissive license. As this is our lowest scoring model, it appears this model does not have sufficient reasoning capacity to make complex reasoning.

Another observation we make is that this model is the only model to get the GPL, LGPL and AGPL licenses wrong as well. However, in this case this has a very different reasoning which appears to be tied to the license text exceeding the model's context window. As such, the model is presented an incomplete question, and gets confused. \\

\textbf{Llama3:} The inaccuracies made by this model are hard to characterise, as they are very varied in nature. This model sets itself apart from the other models as a model which benefits a lot from being "generally right", and thus the Majority-of-15 configuration which we examined it in. The licenses which Deepseek struggled to classify correctly are also licenses which this model struggles to assess, and the explanations it makes for these licenses are very varied and hard to summarize, both for the individual runs that did get it right, and the runs that did not. A general truth is that for every license observed, this model does seem to touch on the specific sections of that license which makes it copyleft if applicable. \\

\newpage\textbf{Qwen3:} This model is the most accurate model in the list. Aside from the IPL-1.0 and Sleepycat licenses which we discussed previously, it is mistaken in its assessment of exactly two more licenses. Firstly and most interestingly, the Artistic-2.0 license is assessed to be copyleft by this model which is wrong. When we look at all 15 runs, we see that it is actually quite adamant of this, answering the same in 14 out of the 15 runs we made. In these runs, it points primarily to section 4 of the license, which governs how Modified Version as Source (a definition provided by the license itself) may be distributed. This section defines that Modified Version as Source may be distributed under a specific set of terms, and it requires one of three conditions to hold:

\begin{enumerate}
	\item The Modified Version as Source must be available \textbf{to the copyright holder of the Standard Version only}, such that they are able to integrate the changes into the Standard Version.
	
	This is not a copyleft requirement, rather it simply ensures that changes may stream back up into the original work.
	
	\item The Modified Version's installation must not interfere with that of the Standard Version for end users.
	
	This too is not a copyleft requirement.
	
	\item Copied verbatim: Allow anyone who receives a copy of the Modified Version to make the Source form of the Modified Version available to others under (i) the Original License or (ii) a license that permits the licensee to freely copy, modify and redistribute the Modified Version using the same licensing terms that apply to the copy that the licensee received, and requires that the Source form of the Modified Version, and of any works derived from it, be made freely available in that license fees are prohibited but Distributor Fees are allowed.
	
	This is in part a copyleft license, in the sense that it limits the licenses under which a derivative work can be created to the Artistic-2.0 license itself, or a license which is constrained in the ways described above.
\end{enumerate}

However, as only one of these three conditions must hold, this license can both be a copyleft license if that clause is chosen, or a permissive license if another clause or implementation is chosen. This appears to be the primary reason of confusion for the Qwen3 model, which is curious as other models do not appear to "over-think" this in this way.

Lastly, the model mistakenly assesses the CPL-1.0 license, but only in the Majority-of-3 configuration. In higher values of the X parameter, we observe that it does correctly identify the copyleft clause contained in the license. For the 2 out of 3 mistakes made for the evaluated configuration, the mistake seems to be the same as Deepseek's difficulty with the EPL licenses, where the model fails to recognise CPL-1.0's clause that requires all source code of derivative works to be distributed under the exact same license, combined with a separate clause requiring the source code of the derivative work to be available within a reasonable time frame upon request of a licensee. Exactly why it misses this in the mistaken runs is hard to reason about, as the model's responses do not go deeply into the decisionmaking leading to the assessment.

\newpage\section{Experiment 2: Combination reasoning}

The experiment as outlined in Chapter~\ref{ch:method} comes down to simply running an algorithm. When we do this, we obtain the following results table, which has the Majority-of-X parameter in the leftmost column. Results in bold are the results which correspond to the Majority-of-X value chosen for the model at the start of this chapter. \\


\begin{table}[h]
	\label{tab:experiment2-large}
	\centering
	\begin{tabular}{|r|c|c|c|c|}
		\hline
		\textbf{X} &  \textbf{Deepseek R1}   &     \textbf{Gemma3}     &     \textbf{Llama3}      &      \textbf{Qwen3}      \\ \hline
		         1 &     86.90\% (10706)     &     79.26\% (9765)      &      80.89\% (9966)      &     94.66\% (11662)      \\
		         3 &     87.15\% (10737)     & \textbf{80.18\% (9878)} &     83.98\% (10346)      & \textbf{93.74\% (11549)} \\
		         5 &     89.43\% (11018)      &     80.19\% (9880)      &     81.18\% (10001)      &     93.74\% (11549)      \\
		         7 & \textbf{90.25\% (11119)} &     80.19\% (9880)      &     82.66\% (10184)      &     94.63\% (11658)      \\
		         9 &     90.97\% (11208)      &     80.19\% (9880)      &     83.57\% (10296)      &     94.63\% (11658)      \\
		        11 &     90.97\% (11208)      &     80.19\% (9880)      &     84.25\% (10380)      &     94.63\% (11658)      \\
		        13 &     90.97\% (11208)      &     80.19\% (9880)      &     85.44\% (10526)      &     94.63\% (11658)      \\
		        15 &     90.04\% (11093)      &     80.19\% (9880)      & \textbf{84.50\% (10411)} &     94.63\% (11658)      \\ \hline
	\end{tabular}
	\caption{Combination reasoning results: Perc\% (Number)}
\end{table}

To make sense of this table, we also list the following observations:
\begin{itemize}
	\item For 116 licenses, a total of $116^2 = 13456$ permutations exist.
	\item 116 of these combinations are combining the license with itself, which is always trivially compatible. These were not included in the results table above.
	\item Of the remaining combinations, the OSADL did not asses 1020. These are also not counted in the results table above.
	\item The remaining number of combinations that were assessed using the proposed assessment algorithm is: $13456 - 116 - 1020 = 12320$
\end{itemize}

An immediately obvious observation is that, despite the complexities outlined in the previous chapters, the proposed automated method of assessing license combinations is able to achieve a relatively high accuracy still overall. However, as we recall, a large number of the license combinations is Permissive-X in the dataset. We've also observed in Experiment 1 that this category is the easiest for the models to classify. For that reason, we also present the following summarized observations when we take out all 9775 cases that have a leading permissive license in the OSADL copyleft table, for the respective X values we've already chosen for each model (which we've placed in the table header next to the model).

\begin{table}[h]
	\label{tab:experiment2-permissive-removed}
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		\textbf{Deepseek R1 (7)} & \textbf{Gemma3 (3)} & \textbf{Llama3 (15)} & \textbf{Qwen3 (3)} \\ \hline
		      80.26\%        &     69.16\%     &     75.80\%     &    83.35\%     \\ \hline
	\end{tabular}
	\caption{Non Permissive-X combination reasoning results: Perc\% (Number)}
\end{table}

When we compare Table~\ref{tab:experiment2-large} to Table~\ref{tab:experiment2-permissive-removed}, we can say that all models are indeed worse at classifying models where a copyleft license may be involved. What's interesting is that all models lose approximately the same amount of accuracy too, all around 10\%. This is a qualitative observation, yet it shows that all models we assessed are somewhat similarly affected by the difficulty of copyleft license assessment. It is also important to point out that all models do consistently get the majority of these assessments right. \\\newpage

When we assess our four models, it is clear that on all cases, \textbf{Qwen3} performs the best, with \textbf{Deepseek R1} following close behind. The other two models are less accurate, but were observed to be significantly faster, again showing the tradeoff between accuracy and speed of inference. \\

Lastly, we also observe that the \textbf{Gemma3} model is very consistent, showing the same result across all X values. We also observe similar, but less consistent behavior with the \textbf{Deepseek R1} model. These behaviors are a direct consequence of their consistency which we already observed in Experiment 1, as this Experiment is a deterministic extension of those results.

\section{Answering the research questions}

At the end of Chapter~\ref{ch:introduction}, we asked two research questions. This section serves to consolidate observations made in these experiments, and formulate those into a clear answer.

\subsection{Important software license properties}

Individually, the license's copyleft property has been shown to be an incredibly powerful indicator of its interaction patterns with other licenses. Interestingly, our experiment did not make a difference between Copyleft Limited and Strong Copyleft license families, and despite this the models still managed to obtain strong accuracy results. This indicates that the incompatibility interaction between the Permissive and Copyleft families is a lot stronger, as opposed to any internal incompatibility interactions for the latter.

Secondarily, a factor which was not explored by our experiment but can still make inference more accurate is explicit compatibility or incompatibility detection. These often take the shape of an upgrade path which was discussed in Chapter~\ref{ch:related-work}, but as licenses can be custom made, explicit statements work as well. \\

It should be noted however that while these factors can be used by an automated reasoning system to assess license combinations at scale, it cannot achieve full accuracy due to the complex nature of legal documents and interactions of specific words, often subject to human curation in the forms of judges interpreting the law. Like with all computer-aided automated reasoning, if there is no clear algorithm, human curation is still a requirement before these decisions are actually used in the real world.

\subsection{Feasibility assessment}

This thesis also asked the question to what extent large language models can be feasibly deployed to answer these license compatibility questions. This thesis answers this question by means of the combination of Experiment 1 and Experiment 2, which shows that this is indeed largely feasible. In the previous section, we already addressed the high importance of human curation, and this cannot be fully removed out of the equation. However, we conclude that this can still be a valuable assistive tool to provide a baseline which can be curated, which is less human-intensive than having to assess an entire matrix of combinations from scratch. \\

To conclude, we address that this thesis is not the end. Rather, we have found that this niche of applying machine learning on software licensing remains largely unexplored by the academic community. This thesis can serve as a baseline, based on which future work can be formed.